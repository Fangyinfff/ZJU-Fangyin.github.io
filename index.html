<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yin Fang (æ–¹å°¹)</title>
  
  <meta name="author" content="Yin Fang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸª½</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yin Fang</name>
              </p>
              <p>I am presently in the third year of my doctoral program (since 2020) in Computer Science at Zhejiang University, supervised by Prof. <a href="https://person.zju.edu.cn/huajun">Huajun Chen</a>, Prof. <a href="https://person.zju.edu.cn/ningyu">Ningyu Zhang</a> and Prof. <a href="https://person.zju.edu.cn/fanxh">Xiaohui Fan</a>.
		      

              </p>
              <p>
                My research pursuits are primarily in the fascinating domain of AI4Science. I am passionate about exploring the interplay between artificial intelligence and scientific inquiry, as well as its potential applications in natural language processing.
                I am currently <span style="color: red;">looking for a post-doc position in the field of AI4Science/NLP/KG</span>. Feel free to reach me if you are interested in my research! 

              </p>
              <p style="text-align:center">
                <a href="mailto:fangyin@zju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=LBFhHMgAAAAJ;hl=en">Google Scholar</a>
                &nbsp/&nbsp
                <a href="https://dblp.org/pid/231/7716.html">DBLP</a>
                <a href="https://github.com/ZJU-Fangyin">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/YinFang22900365">Twitter</a>
              </p>

            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/fy.JPG"><img style="width:50%;max-width:50" alt="profile photo"
                  src="images/fy.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <heading>Research</heading>(* indicates equal contribution)

          </td>
            </tr>
        </tbody></table>
        <style>
          img {
            border-radius: 15px;
          }
        </style>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/KANO.png" alt="tag2text" width="190" height="110">
            </td>
            <td width="75%" valign="middle">
              <a href="https://recognize-anything.github.io/">
                <papertitle> Knowledge Graph-enhanced Molecular Contrastive Learning with Functional Prompt </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>,
              Qiang Zhang, Ningyu Zhang, Zhuo Chen, Xiang Zhuang, Xin Shao, Xiaohui Fan, Huajun Chen
              <br>
              <em>Nature Machine Intelligence (IF=25.90)</em>,
              2023
              <br>
              <a href="https://github.com/HICAI-ZJU/KANO">project page</a>
              /
              <a href="https://www.nature.com/articles/s42256-023-00654-0">Paper</a>
              <p></p>
              <p><strong>KANO</strong> is a Knowledge graph-enhanced molecular contrAstive learning framework with fuNctional prOmpt, designed to exploit fundamental domain knowledge in both pre-training and fine-tuning phases.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/KCL.png" alt="tag2text" width="190" height="110">
            </td>
            <td width="75%" valign="middle">
              <a href="https://recognize-anything.github.io/">
                <papertitle> Molecular Contrastive Learning with Chemical Element Knowledge Graph </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>,
              Qiang Zhang, Haihong Yang, Xiang Zhuang, Shumin Deng, Wen Zhang, Ming Qin, Zhuo Chen, Xiaohui Fan, Huajun Chen
              <br>
              <em>AAAI</em>,
              2022
              <br>
              <a href="https://github.com/ZJU-Fangyin/KCL">project page</a>
              /
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20313">Paper</a>
              <p></p>
              <p><strong>KCL</strong> is a novel Knowledge-enhanced Contrastive Learning framework for molecular representation learning, built upon a Chemical Element Knowledge Graph (KG) that summarizes microscopic associations between elements.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bulk2space.jpeg" alt="tag2text" width="190" height="110">
            </td>
            <td width="75%" valign="middle">
              <a href="https://recognize-anything.github.io/">
                <papertitle> De Novo Analysis of Bulk RNA-seq Data at Spatially Resolved Single-cell Resolution </papertitle>
              </a>
              <br>
              Jie Liao*, Jingyang Qian*, <strong>Yin Fang*</strong>, Zhuo Chen*, Xiang Zhuang*, Ningyu Zhang, Xin Shao, Yining Hu, Penghui Yang, Junyun Cheng, Yang Hu, Lingqi Yu, Haihong Yang, Jinlu Zhang, Xiaoyan Lu, Li Shao, Dan Wu, Yue Gao, Huajun Chen, Xiaohui Fan
              <br>
              <em>Nature Communications (Editors' Highlights, Top 25 in 2022) (IF=17.69)</em>,
              2022
              <br>
              <a href="https://github.com/ZJUFanLab/bulk2space">project page</a>
              /
              <a href="https://www.nature.com/articles/s41467-022-34271-z">Paper</a>
              <p></p>
              <p><strong>Bulk2Space</strong> is a two-step spatial deconvolution method based on deep learning frameworks, which converts bulk transcriptomes into spatially resolved single-cell expression profiles.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/scspace.jpg" alt="tag2text" width="190" height="110">
            </td>
            <td width="75%" valign="middle">
              <a href="https://recognize-anything.github.io/">
                <papertitle> Reconstruction of the cell pseudo-space from single-cell RNA sequencing data with scSpace </papertitle>
              </a>
              <br>
              Jingyang Qian*, Jie Liao*, Ziqi Liu*, Ying Chi*, <strong>Yin Fang*</strong>, Yanrong Zheng, Xin Shao, Bingqi Liu, Yongjin Cui, Wenbo Guo, Yining Hu, Hudong Bao, Penghui Yang, Qian Chen, Mingxiao Li, Bing Zhang, Xiaohui Fan
              <br>
              <em>Nature Communications (Editors' Highlights) (IF=17.69)</em>,
              2023
              <br>
              <a href="https://github.com/ZJUFanLab/scSpace">project page</a>
              /
              <a href="https://www.nature.com/articles/s41467-023-38121-4">Paper</a>
              <p></p>
              <p><strong>scSpace</strong> (single-cell and spatial position associated co-embeddings) is an integrative algorithm that integrates spatial transcriptome data to reconstruct spatial associations of single cells within scRNA-seq data.</p>
            </td>
          </tr>


     
    </tbody></table>





			
      </td>
    </tr>
  </table>
</body>

</html>
