<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yin Fang (ÊñπÂ∞π)</title>
  
  <meta name="author" content="Yin Fang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%30>üêï</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yin Fang</name>
              </p>
              <p>I am presently in the fourth year of my doctoral program (since 2020) in Computer Science at Zhejiang University, supervised by Prof. <a href="https://person.zju.edu.cn/huajun">Huajun Chen</a>, Prof. <a href="https://person.zju.edu.cn/ningyu">Ningyu Zhang</a> and Prof. <a href="https://person.zju.edu.cn/fanxh">Xiaohui Fan</a>.
		      

              </p>
              <p>
                My research pursuits are primarily in the fascinating domain of AI4Science. I am passionate about exploring the interplay between artificial intelligence and scientific inquiry, as well as its potential applications in natural language processing.</p>
               <p> I am currently <span style="color: red;">looking for a post-doc position in the field of AI4Science/NLP/KG</span>. Feel free to reach me if you are interested in my research! 

              </p>
              <p style="text-align:center">
                <a href="mailto:fangyin@zju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=4rWspjsAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://dblp.org/pid/231/7716.html">DBLP</a> &nbsp/&nbsp
                <a href="https://github.com/ZJU-Fangyin">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/YinFang22900365">Twitter</a>
              </p>

            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/fy.JPG"><img style="width:55%;max-width:40" alt="profile photo"
                  src="images/fy.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <heading>Research</heading>(* indicates equal contribution)

          </td>
            </tr>
        </tbody></table>
        <style>
          img {
            border-radius: 15px;
          }
        </style>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/KANO.png" alt="KANO" width="190" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/HICAI-ZJU/KANO">
                <papertitle> Knowledge Graph-enhanced Molecular Contrastive Learning with Functional Prompt </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>,
              Qiang Zhang, Ningyu Zhang, Zhuo Chen, Xiang Zhuang, Xin Shao, Xiaohui Fan, Huajun Chen
              <br>
              <em>Nature Machine Intelligence (IF=25.90)</em>,
              2023
              <br>
              <a href="https://github.com/HICAI-ZJU/KANO">Project page</a>
              /
              <a href="https://www.nature.com/articles/s42256-023-00654-0">Paper</a>
              <p></p>
              <p><strong>KANO</strong> is a Knowledge graph-enhanced molecular contrAstive learning framework with fuNctional prOmpt, designed to exploit fundamental domain knowledge in both pre-training and fine-tuning phases.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/molinstructions.png" alt="molinstructions" width="190" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/zjunlp/Mol-Instructions">
                <papertitle> Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen
              <br>
              <em>ICLR 2024</em>,
              2023
              <br>
              <a href="https://github.com/zjunlp/Mol-Instructions">Project page</a>
              /
              <a href="https://arxiv.org/abs/2306.08018">Paper</a>
              <p></p>
              <p><strong>Mol-Instructions</strong> is a Large-Scale Biomolecules Instruction Dataset for Large Language Models.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/molgen.png" alt="molgen" width="190" height="60">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/zjunlp/MolGen">
                <papertitle> Domain-Agnostic Molecular Generation with Self-feedback </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>, Ningyu Zhang, Zhuo Chen, Lingbing Guo, Xiaohui Fan, Huajun Chen
              <br>
              <em>ICLR 2024</em>,
              2023
              <br>
              <a href="https://github.com/zjunlp/MolGen">Project page</a>
              /
              <a href="https://arxiv.org/abs/2301.11259">Paper</a>
              <p></p>
              <p><strong>MolGen</strong> is a pre-trained molecular language model tailored specifically for molecule generation.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/KCL.png" alt="KCL" width="190" height="60">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/ZJU-Fangyin/KCL">
                <papertitle> Molecular Contrastive Learning with Chemical Element Knowledge Graph </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>,
              Qiang Zhang, Haihong Yang, Xiang Zhuang, Shumin Deng, Wen Zhang, Ming Qin, Zhuo Chen, Xiaohui Fan, Huajun Chen
              <br>
              <em>AAAI</em>,
              2022
              <br>
              <a href="https://github.com/ZJU-Fangyin/KCL">Project page</a>
              /
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20313">Paper</a>
              <p></p>
              <p><strong>KCL</strong> is a novel Knowledge-enhanced Contrastive Learning framework for molecular representation learning, built upon a Chemical Element Knowledge Graph (KG) that summarizes microscopic associations between elements.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bulk2space.jpeg" alt="bulk2space" width="190" height="110">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/ZJUFanLab/bulk2space">
                <papertitle> De Novo Analysis of Bulk RNA-seq Data at Spatially Resolved Single-cell Resolution </papertitle>
              </a>
              <br>
              Jie Liao*, Jingyang Qian*, <strong>Yin Fang*</strong>, Zhuo Chen*, Xiang Zhuang*, Ningyu Zhang, Xin Shao, Yining Hu, Penghui Yang, Junyun Cheng, Yang Hu, Lingqi Yu, Haihong Yang, Jinlu Zhang, Xiaoyan Lu, Li Shao, Dan Wu, Yue Gao, Huajun Chen, Xiaohui Fan
              <br>
              <em>Nature Communications (Editors' Highlights, Top 25 in 2022) (IF=17.69)</em>,
              2022
              <br>
              <a href="https://github.com/ZJUFanLab/bulk2space">Project page</a>
              /
              <a href="https://www.nature.com/articles/s41467-022-34271-z">Paper</a>
              <p></p>
              <p><strong>Bulk2Space</strong> is a two-step spatial deconvolution method based on deep learning frameworks, which converts bulk transcriptomes into spatially resolved single-cell expression profiles.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/scspace.jpg" alt="scspace" width="190" height="70">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/ZJUFanLab/scSpace">
                <papertitle> Reconstruction of the cell pseudo-space from single-cell RNA sequencing data with scSpace </papertitle>
              </a>
              <br>
              Jingyang Qian*, Jie Liao*, Ziqi Liu*, Ying Chi*, <strong>Yin Fang</strong>, Yanrong Zheng, Xin Shao, Bingqi Liu, Yongjin Cui, Wenbo Guo, Yining Hu, Hudong Bao, Penghui Yang, Qian Chen, Mingxiao Li, Bing Zhang, Xiaohui Fan
              <br>
              <em>Nature Communications (Editors' Highlights) (IF=17.69)</em>,
              2023
              <br>
              <a href="https://github.com/ZJUFanLab/scSpace">Project page</a>
              /
              <a href="https://www.nature.com/articles/s41467-023-38121-4">Paper</a>
              <p></p>
              <p><strong>scSpace</strong> (single-cell and spatial position associated co-embeddings) is an integrative algorithm that integrates spatial transcriptome data to reconstruct spatial associations of single cells within scRNA-seq data.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/jcim.jpeg" alt="jcim" width="190" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c01977">
                <papertitle> The Future of Molecular Studies through the Lens of Large Language Models </papertitle>
              </a>
              <br>
              Jinlu Zhang, <strong>Yin Fang</strong>, Xin Shao, Huajun Chen, Ningyu Zhang, Xiaohui Fan
              <br>
              <em>Journal of Chemical Information and Modeling (IF=6.16)</em>,
              2023
              <br>
              <a href="https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c01977">Paper</a>
              <p></p>
              <p>This paper proposes possible directions for future molecular science research. These suggestions aim to forge new paths for exploring the intricacies of molecular structures, potentially bringing new efficiencies and innovations in the field.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/deepsorption.png" alt="deepsorption" width="190" height="70">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.nature.com/articles/s41467-023-42863-6">
                <papertitle> Direct prediction of gas adsorption via spatial atom interaction learning </papertitle>
              </a>
              <br>
              Jiyu Cui, Fang Wu, Wen Zhang, Lifeng Yang, Jianbo Hu, <strong>Yin Fang</strong>, Peng Ye, Qiang Zhang, Xian Suo, Yiming Mo, Xili Cui, Huajun Chen, Huabin Xing
              <br>
              <em>Nature Communications (IF=17.69)</em>,
              2023
              <br>
              <a href="https://github.com/DeepSorption/DeepSorption1.0">Project page</a>
              /
              <a href="https://www.nature.com/articles/s41467-023-38121-4">Paper</a>
              <p></p>
              <p><strong>DeepSorption</strong> is a spatial atom interaction learning network that realizes accurate, fast, and direct structure-adsorption prediction with only information of atomic coordinate and chemical element types.</p>
            </td>
          </tr>
		

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/paradigm.png" alt="paradigm" width="190" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2202.10587">
                <papertitle> Knowledge-informed Molecular Learning: A Survey on Paradigm Transfer </papertitle>
              </a>
              <br>
              <strong>Yin Fang</strong>, Qiang Zhang, Zhuo Chen, Xiaohui Fan, Huajun Chen
              <br>
              <em>Preprint</em>,
              2023
              <br>
              <a href="https://arxiv.org/abs/2202.10587">arXiv</a>
              <p></p>
              <p>This paper offers a comprehensive review of molecular learning, with a focus on the knowledge-informed paradigm transfer approach. It provides an overview of the various paradigms and their technical solutions, as well as a summary of the external domain knowledge used to guide the transfer process for each molecular learning task.</p>
            </td>
          </tr>
		
    </tbody></table>


			
      </td>
    </tr>
  </table>
</body>

</html>
